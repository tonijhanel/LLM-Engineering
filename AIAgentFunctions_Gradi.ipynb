{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbNSN9HMSvuH4Fexm4MZ39",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tonijhanel/LLM-Engineering/blob/main/AIAgentFunctions_Gradi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AI Agent Functions and Gradio UI"
      ],
      "metadata": {
        "id": "MEl8OyCaKVot"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installs and Imports"
      ],
      "metadata": {
        "id": "piOoEFksKNzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv\n",
        "!pip install openai\n",
        "!pip install gradio"
      ],
      "metadata": {
        "id": "GsAZc6zmJr74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNlcBFeuJBFH"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import os\n",
        "import json\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "import gradio as gr\n",
        "from google.colab import userdata\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to OPEN AI API"
      ],
      "metadata": {
        "id": "Zg_VfyIJKQuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "if openai_api_key:\n",
        "    print(\"OpenAI API Key exists\")\n",
        "else:\n",
        "    print(\"OpenAI API Key not set\")\n",
        "\n",
        "MODEL = \"gpt-4o-mini\"\n",
        "openai = OpenAI(api_key=openai_api_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9j5BypHSJqut",
        "outputId": "65c0a038-f51c-4b99-cea8-93ac8c12a246"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI API Key exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are a helpful assistant for an Airline called FlightAI. \"\n",
        "system_message += \"Give short, courteous answers, no more than 1 sentence. \"\n",
        "system_message += \"Always be accurate. If you don't know the answer, say so.\""
      ],
      "metadata": {
        "id": "E6sArcwnJ_bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Ticket Price Tool"
      ],
      "metadata": {
        "id": "YdetqHpBKkND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ticket_prices = {\"london\": \"$799\", \"paris\": \"$899\", \"tokyo\": \"$1400\", \"berlin\": \"$499\"}\n",
        "\n",
        "def get_ticket_price(destination_city):\n",
        "    print(f\"Tool get_ticket_price called for {destination_city}\")\n",
        "    city = destination_city.lower()\n",
        "    return ticket_prices.get(city, \"Unknown\")"
      ],
      "metadata": {
        "id": "X4lu2DXTKnEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_ticket_price(\"London\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "3HHKr9WvKqUs",
        "outputId": "e3719ec5-7b6a-4230-c732-fa6d61b70626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tool get_ticket_price called for London\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'$799'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define price_function structure\n",
        "\n",
        "price_function = {\n",
        "    \"name\": \"get_ticket_price\",\n",
        "    \"description\": \"Get the price of a return ticket to the destination city. Call this whenever you need to know the ticket price, for example when a customer asks 'How much is a ticket to this city'\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"destination_city\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"The city that the customer wants to travel to\",\n",
        "            },\n",
        "        },\n",
        "        \"required\": [\"destination_city\"],\n",
        "        \"additionalProperties\": False\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "UN4ibkDeKsGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define tools\n",
        "\n",
        "tools = [{\"type\": \"function\", \"function\": price_function}]"
      ],
      "metadata": {
        "id": "0ADsxeC9KySi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_tool_call(message):\n",
        "    tool_call = message.tool_calls[0]\n",
        "    arguments = json.loads(tool_call.function.arguments)\n",
        "    city = arguments.get('destination_city')\n",
        "    price = get_ticket_price(city)\n",
        "    response = {\n",
        "        \"role\": \"tool\",\n",
        "        \"content\": json.dumps({\"destination_city\": city,\"price\": price}),\n",
        "        \"tool_call_id\": tool_call.id\n",
        "    }\n",
        "    return response, city"
      ],
      "metadata": {
        "id": "0cumMSawM8xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add Image Generation"
      ],
      "metadata": {
        "id": "gFm0ZrUxNK85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "\n",
        "def artist(city):\n",
        "    image_response = openai.images.generate(\n",
        "            model=\"dall-e-3\",\n",
        "            prompt=f\"An image representing a vacation in {city}, showing tourist spots and everything unique about {city}, in a vibrant pop-art style\",\n",
        "            size=\"1024x1024\",\n",
        "            n=1,\n",
        "            response_format=\"b64_json\",\n",
        "        )\n",
        "    image_base64 = image_response.data[0].b64_json\n",
        "    image_data = base64.b64decode(image_base64)\n",
        "    return Image.open(BytesIO(image_data))"
      ],
      "metadata": {
        "id": "ijJZQK6gNMtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = artist(\"New York City\")\n",
        "display(image)"
      ],
      "metadata": {
        "id": "40GVo9zzNRBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add Audio Features"
      ],
      "metadata": {
        "id": "a_wEh9zyNCY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "from pydub.playback import play\n",
        "from io import BytesIO\n",
        "from IPython.display import Audio\n",
        "\n",
        "def talker(message, voice=\"nova\"):\n",
        "    response = openai.audio.speech.create(\n",
        "        model=\"tts-1\",\n",
        "        voice=voice,\n",
        "        input=message)\n",
        "\n",
        "    audio_stream = BytesIO(response.content)\n",
        "    output_filename = \"output_audio.mp3\"\n",
        "    with open(output_filename, \"wb\") as f:\n",
        "        f.write(audio_stream.read())\n",
        "\n",
        "    # Auto Play the generated audio\n",
        "    #display(Audio(output_filename, autoplay=True))\n",
        "\n",
        "    # for colab implementation\n",
        "    return output_filename"
      ],
      "metadata": {
        "id": "ctDXCDglK230"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "talker(\"Well, hi there\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ZiqV96CyLEA6",
        "outputId": "688f6f5a-610a-45ef-9586-b7f31cd5c8fd"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'output_audio.mp3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Chat Functionality"
      ],
      "metadata": {
        "id": "VO7WY41gMqfw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def chat(history, voice_selection, current_image):\n",
        "    \"\"\"\n",
        "    Processes user chat input, interacts with the OpenAI model, handles tool calls,\n",
        "    and generates an audio response.\n",
        "\n",
        "    Args:\n",
        "        history (list): A list of message dictionaries representing the conversation history.\n",
        "        voice_selection (str): The voice to use for the audio response.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the updated history and any generated image (or None).\n",
        "    \"\"\"\n",
        "    messages = [{\"role\": \"system\", \"content\": system_message}] + history\n",
        "    response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
        "    #image = \"https://drive.google.com/uc?export=view&id=1T6SRoU06_X8vPtcAwgtJFevEMjEOYva-\"\n",
        "    image = current_image\n",
        "\n",
        "    if response.choices[0].finish_reason==\"tool_calls\":\n",
        "        message = response.choices[0].message\n",
        "        response, city = handle_tool_call(message)\n",
        "        messages.append(message)\n",
        "        messages.append(response)\n",
        "        if city and city.strip():\n",
        "          image = artist(city)\n",
        "        response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
        "\n",
        "    reply = response.choices[0].message.content\n",
        "    history += [{\"role\":\"assistant\", \"content\":reply}]\n",
        "\n",
        "    # Comment out or delete the next line if you'd rather skip Audio for now..\n",
        "    #talker(reply, voice_selection)\n",
        "\n",
        "    # for colab implemenation\n",
        "    audio_file_path = talker(reply, voice_selection)\n",
        "    return history, image, audio_file_path"
      ],
      "metadata": {
        "id": "qajE1fBMLRvC"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Gradio UI"
      ],
      "metadata": {
        "id": "YUytDkKBNgXl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the cell below to use chatbot"
      ],
      "metadata": {
        "id": "QjZTx8BjTSvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gradio import themes\n",
        "placeholder_link = \"https://drive.google.com/uc?export=view&id=1T6SRoU06_X8vPtcAwgtJFevEMjEOYva-\"\n",
        "\n",
        "with gr.Blocks(theme=themes.Monochrome()) as ui:\n",
        "\n",
        "    gr.Markdown(\"# My Awesome AI Assistant\")\n",
        "\n",
        "    with gr.Row():\n",
        "        chatbot = gr.Chatbot(height=500, type=\"messages\")\n",
        "        image_output = gr.Image(value=placeholder_link, height=500)\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=2):\n",
        "            with gr.Row():\n",
        "                entry = gr.Textbox(\n",
        "                    placeholder=\"Chat with our AI Assistant:\",\n",
        "                    label=\"Chat with our AI Assistant:\",\n",
        "                    scale=2,\n",
        "                    container=False)\n",
        "\n",
        "                submit_button = gr.Button(\n",
        "                    value=\"âž¤\",\n",
        "                    variant=\"primary\",\n",
        "                    scale=0,\n",
        "                    elem_classes=[\"submit-button\"]\n",
        "                )\n",
        "        with gr.Column(scale=0):\n",
        "            voice_dropdown = gr.Dropdown(\n",
        "            choices=[(\"Alloy\", \"alloy\"), (\"Echo\", \"echo\"), (\"Fable\", \"fable\"), (\"Onyx\",\"onyx\"), (\"Nova\", \"nova\"), (\"Shimmer\", \"shimmer\")],\n",
        "            label=\"Select Voice\",\n",
        "            value=\"alloy\",\n",
        "            scale=1)\n",
        "\n",
        "    with gr.Row():\n",
        "       audio_output = gr.Audio(label=\"AI Voice Response\", autoplay=True)\n",
        "\n",
        "    with gr.Row():\n",
        "        clear = gr.Button(\"Clear\")\n",
        "\n",
        "\n",
        "    def do_entry(message, history, voice_selection):\n",
        "        history += [{\"role\":\"user\", \"content\":message}]\n",
        "        return \"\", history\n",
        "\n",
        "    entry.submit(do_entry, inputs=[entry, chatbot, voice_dropdown], outputs=[entry, chatbot]).then(\n",
        "        chat, inputs=[chatbot, voice_dropdown, image_output], outputs=[chatbot, image_output, audio_output ]\n",
        "    )\n",
        "\n",
        "    submit_button.click(do_entry, inputs=[entry, chatbot, voice_dropdown], outputs=[entry, chatbot]).then(\n",
        "        chat, inputs=[chatbot, voice_dropdown, image_output], outputs=[chatbot, image_output, audio_output ]\n",
        "    )\n",
        "\n",
        "\n",
        "    clear.click(lambda: None, inputs=None, outputs=chatbot, queue=False)\n",
        "\n",
        "ui.launch(inbrowser=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "9pt7LGfJL2ib",
        "outputId": "3e164d37-a69d-4cb8-f852-a942a6b124ec"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://91a1ae124f021e2792.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://91a1ae124f021e2792.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sbCZ6MC9Uh7r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}